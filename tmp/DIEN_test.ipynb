{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as nn\n",
    "\n",
    "from layer import attention, dice, AUGRU\n",
    "from utils import sequence_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dim = 8\n",
    "cate_dim = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造虚拟数据\n",
    "user_emb = np.random.rand(32,8+6)\n",
    "item_join_emb  = np.random.rand(32,8+6)\n",
    "hist_join_emb  = np.random.rand(32,20,8+6)\n",
    "length = np.random.randint(1,21,(32,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 13,  1,  5,  2,  5, 19,  4,  9,  1, 12, 15, 12, 12,  9,  2,  4,\n",
       "       12, 20,  8, 15,  8, 15,  5, 20, 17, 16,  3, 13,  3, 12,  9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_join_emb = tf.cast(item_join_emb,tf.float32)\n",
    "hist_join_emb = tf.cast(hist_join_emb,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_layers=[200,88,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = tf.keras.Sequential()\n",
    "fc.add(nn.BatchNormalization())\n",
    "for dim_layer in dim_layers[:-1]:\n",
    "    fc.add(nn.Dense(dim_layer, activation='sigmoid'))\n",
    "fc.add(nn.Dense(dim_layers[-1], activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一次GRU\n",
    "hist_gru_emb = nn.GRU(item_dim+cate_dim, return_sequences=True)(hist_join_emb) # (32, 20, 14)\n",
    "# 利用第一次GRU得到的结果计算attention值，直接采用矩阵乘法进行计算向量之间的点积作为attention:(32,1,14)x(32,14,20)\n",
    "tmp_attention = tf.matmul(tf.expand_dims(item_join_emb, 1), hist_gru_emb, transpose_b=True) # (32, 1, 20)\n",
    "# 此处的(1,20)代表每一个user的被推荐的item与history序列（长度20）的item的相似度，一共20个相似度，将其作为attention\n",
    "# 其中有效attention与history的有效长度相同，因此对其进行mask操作。此处不能用0-1mask,考虑到\n",
    "# 后期要用到softmax 进行归一化，所以将无效值填充为负数无穷大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask机制\n",
    "hist_mask = tf.sequence_mask(length, max(length), dtype=tf.bool)\n",
    "hist_mask = tf.expand_dims(hist_mask, axis=1)\n",
    "\n",
    "paddings = tf.ones_like(tmp_attention) * (-2 ** 32 + 1)\n",
    "\n",
    "tmp_attention = tf.where(hist_mask, tmp_attention, paddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_attn = tf.nn.softmax(tmp_attention)  # 32, 1, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hist_hid_emb = tf.zeros_like(hist_gru_emb[:,0,:])   # (32,14) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_augru = AUGRU(item_dim+cate_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for in_emb, in_att in zip(tf.transpose(hist_gru_emb, [1,0,2]),  # (20,32,14)\n",
    "                                  tf.transpose(hist_attn, [2,0,1])):  # (20,32,1)\n",
    "            hist_hid_emb = hist_augru(in_emb, hist_hid_emb, in_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2546, shape=(32, 14), dtype=float32, numpy=\n",
       "array([[ 0.14648642,  0.13651685,  0.15864761, -0.17104676,  0.01430989,\n",
       "         0.18607275, -0.01829286, -0.09990608,  0.005282  , -0.05237443,\n",
       "         0.04945968,  0.11195529, -0.23012908,  0.09918956],\n",
       "       [ 0.13782021,  0.14846215,  0.14881082, -0.1659787 ,  0.03232015,\n",
       "         0.18659937,  0.00151965, -0.119367  ,  0.02819161, -0.04637884,\n",
       "         0.03524139,  0.11855108, -0.24317914,  0.07702108],\n",
       "       [ 0.00978375,  0.04397272,  0.06917825, -0.10100146,  0.0051847 ,\n",
       "         0.08837738, -0.0102619 , -0.03727499, -0.02951335, -0.09204036,\n",
       "         0.18127629,  0.12526385, -0.13742772,  0.1396219 ],\n",
       "       [ 0.1591132 ,  0.06857026,  0.0869699 , -0.16727331,  0.01361358,\n",
       "         0.16379169,  0.00281742, -0.08893263,  0.02659938,  0.00947718,\n",
       "         0.07453416,  0.06415336, -0.22427154,  0.02158549],\n",
       "       [ 0.14735484,  0.05605894,  0.12703943, -0.19016394, -0.06699548,\n",
       "         0.16076122, -0.02679097, -0.13024369, -0.02409249, -0.0397788 ,\n",
       "         0.1430756 ,  0.08635141, -0.2617776 ,  0.06905161],\n",
       "       [ 0.16929173,  0.12085348,  0.16154142, -0.19068073,  0.01541699,\n",
       "         0.18178093, -0.01725264, -0.09553871, -0.02069868, -0.04754975,\n",
       "         0.07789166,  0.12753126, -0.24543959,  0.10092672],\n",
       "       [ 0.13497703,  0.12163746,  0.14945647, -0.137593  ,  0.04534255,\n",
       "         0.1717696 , -0.02211497, -0.08750821,  0.02692562, -0.03765364,\n",
       "         0.03628099,  0.11950791, -0.19849034,  0.08982848],\n",
       "       [ 0.13789079,  0.06562148,  0.09605557, -0.15384328,  0.02346298,\n",
       "         0.17140126, -0.03054756, -0.05244024,  0.02259555,  0.00496931,\n",
       "         0.06878843,  0.05750329, -0.20092784,  0.06321283],\n",
       "       [ 0.12915145,  0.1582694 ,  0.1440339 , -0.14474726,  0.03410441,\n",
       "         0.15818578, -0.02923682, -0.1281087 , -0.00127742, -0.02900167,\n",
       "         0.04022016,  0.12504561, -0.22610268,  0.06655857],\n",
       "       [ 0.05986844,  0.04296293,  0.08555971, -0.16160709, -0.01993971,\n",
       "         0.1497446 ,  0.02507612, -0.0701716 , -0.0633823 , -0.04095964,\n",
       "         0.17401518,  0.15265122, -0.19652171,  0.12451527],\n",
       "       [ 0.1573829 ,  0.07587   ,  0.14257567, -0.19170523, -0.01471234,\n",
       "         0.20358264, -0.01095365, -0.09536815,  0.04421298, -0.0443252 ,\n",
       "         0.09356561,  0.1013637 , -0.2589913 ,  0.09286643],\n",
       "       [ 0.13852258,  0.12003925,  0.12051666, -0.17186144,  0.03413283,\n",
       "         0.17650789,  0.00396582, -0.0996625 ,  0.01282968, -0.03180283,\n",
       "         0.06210768,  0.11312373, -0.23886177,  0.07048311],\n",
       "       [ 0.1479032 ,  0.12725712,  0.11500047, -0.14383268,  0.05160715,\n",
       "         0.16086394, -0.01379017, -0.10166551,  0.03673396, -0.0195392 ,\n",
       "         0.03843175,  0.09707964, -0.21023327,  0.04359506],\n",
       "       [ 0.14489123,  0.15616655,  0.1490888 , -0.17485325,  0.0189942 ,\n",
       "         0.17372139, -0.00803222, -0.12976915,  0.00490031, -0.0590465 ,\n",
       "         0.03898352,  0.1203251 , -0.24961053,  0.06617011],\n",
       "       [ 0.07251426,  0.11477541,  0.09085289, -0.0837998 ,  0.06409439,\n",
       "         0.12322887, -0.01833752, -0.09291033,  0.01390729, -0.02124689,\n",
       "         0.01853188,  0.10305086, -0.16465893,  0.06230647],\n",
       "       [ 0.11438292,  0.05305279,  0.10955566, -0.10369021,  0.00747649,\n",
       "         0.12903063, -0.03946865, -0.04606885, -0.00470338, -0.04254151,\n",
       "         0.03402953,  0.04323686, -0.13058622,  0.07559538],\n",
       "       [ 0.13169047,  0.16258703,  0.12416422, -0.11941246,  0.06697435,\n",
       "         0.13192569, -0.04240146, -0.1382181 ,  0.00768455, -0.01698425,\n",
       "         0.03189496,  0.1225079 , -0.22764057,  0.03872277],\n",
       "       [ 0.12984458,  0.15138468,  0.14092273, -0.17405634,  0.03607973,\n",
       "         0.18311587,  0.01629498, -0.08702256,  0.0154857 , -0.05742566,\n",
       "         0.05082706,  0.12332054, -0.22169513,  0.08615684],\n",
       "       [ 0.12697311,  0.09467858,  0.13125384, -0.14797774,  0.0156373 ,\n",
       "         0.15407245, -0.01543137, -0.07993069,  0.01393671, -0.03865325,\n",
       "         0.07675336,  0.10389018, -0.2014463 ,  0.09311437],\n",
       "       [ 0.13004948,  0.08505873,  0.10453728, -0.1935793 ,  0.02298447,\n",
       "         0.1796972 ,  0.04520041, -0.04307823,  0.01888733, -0.03447789,\n",
       "         0.10371166,  0.11014904, -0.22496822,  0.09663697],\n",
       "       [ 0.15637967,  0.12792903,  0.15592669, -0.17952475,  0.01919058,\n",
       "         0.19742545, -0.02236524, -0.10349122,  0.00560143, -0.04754502,\n",
       "         0.07075436,  0.1280649 , -0.24383982,  0.10387097],\n",
       "       [ 0.16446386,  0.09822033,  0.15319853, -0.20787987, -0.01932583,\n",
       "         0.19986157, -0.01450429, -0.07619675,  0.00695386, -0.062429  ,\n",
       "         0.10511326,  0.0905114 , -0.26550162,  0.11678032],\n",
       "       [ 0.11556319,  0.11961344,  0.12611575, -0.16118607,  0.01060642,\n",
       "         0.16667569,  0.00859694, -0.10822652,  0.00185163, -0.06007417,\n",
       "         0.08289742,  0.12633906, -0.22309625,  0.09391417],\n",
       "       [ 0.14390686,  0.07917313,  0.13724364, -0.13182545,  0.01134613,\n",
       "         0.16440062, -0.03257076, -0.1287932 ,  0.02351296, -0.05385331,\n",
       "         0.07468691,  0.11410718, -0.21335948,  0.07781684],\n",
       "       [ 0.14065541,  0.12570804,  0.13280272, -0.19021133,  0.00378378,\n",
       "         0.19617759, -0.00877875, -0.12230103,  0.01926226, -0.04487791,\n",
       "         0.08384962,  0.11326668, -0.27040583,  0.08072557],\n",
       "       [ 0.14781964,  0.1072965 ,  0.14793266, -0.16583307,  0.02075508,\n",
       "         0.17839107, -0.03063934, -0.09582043,  0.0217503 , -0.03304049,\n",
       "         0.08317754,  0.12497121, -0.23740238,  0.09743966],\n",
       "       [ 0.12604864,  0.08539702,  0.10999095, -0.16526225,  0.01107567,\n",
       "         0.15823056, -0.00671939, -0.07197884,  0.0243973 , -0.04376848,\n",
       "         0.07912064,  0.07934097, -0.21819279,  0.07405099],\n",
       "       [ 0.13470697,  0.06529775,  0.12431435, -0.13906181,  0.00540128,\n",
       "         0.15516901, -0.04514284, -0.05903388,  0.0219172 , -0.04297803,\n",
       "         0.08115885,  0.07564944, -0.18448405,  0.09245192],\n",
       "       [ 0.14045793,  0.10517301,  0.1171943 , -0.15422767,  0.02929255,\n",
       "         0.1541328 , -0.02195152, -0.07712396,  0.02564836, -0.03046478,\n",
       "         0.06841449,  0.08215568, -0.21018334,  0.06352121],\n",
       "       [ 0.14245497,  0.09230983,  0.12935033, -0.15743497,  0.02579435,\n",
       "         0.16322047, -0.00326726, -0.05094752, -0.00287336, -0.06132315,\n",
       "         0.07427199,  0.09880868, -0.1713708 ,  0.08626675],\n",
       "       [ 0.12801094,  0.09198072,  0.137615  , -0.15699252,  0.01147004,\n",
       "         0.17634691, -0.02856377, -0.10050517,  0.01694326, -0.05097748,\n",
       "         0.07968149,  0.11239174, -0.23035268,  0.10076143],\n",
       "       [ 0.14940092,  0.08560565,  0.11820422, -0.11831942,  0.0286001 ,\n",
       "         0.14899439, -0.0161958 , -0.09027104,  0.02725209, -0.01046806,\n",
       "         0.04559619,  0.08970471, -0.1697708 ,  0.04844797]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_hid_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " join_emb = tf.concat([user_emb, item_join_emb, hist_hid_emb], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2549, shape=(32, 42), dtype=float32, numpy=\n",
       "array([[ 0.85401475,  0.17966537,  0.6078861 , ...,  0.11195529,\n",
       "        -0.23012908,  0.09918956],\n",
       "       [ 0.5997213 ,  0.82931554,  0.59010124, ...,  0.11855108,\n",
       "        -0.24317914,  0.07702108],\n",
       "       [ 0.9350175 ,  0.7345248 ,  0.08661092, ...,  0.12526385,\n",
       "        -0.13742772,  0.1396219 ],\n",
       "       ...,\n",
       "       [ 0.5221897 ,  0.48507   ,  0.51957184, ...,  0.09880868,\n",
       "        -0.1713708 ,  0.08626675],\n",
       "       [ 0.06606931,  0.81279397,  0.529611  , ...,  0.11239174,\n",
       "        -0.23035268,  0.10076143],\n",
       "       [ 0.03532085,  0.32427463,  0.46540797, ...,  0.08970471,\n",
       "        -0.1697708 ,  0.04844797]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.squeeze(fc(join_emb)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2685, shape=(2,), dtype=float32, numpy=array([ 1.2612679, -1.0014291], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = tf.keras.activations.sigmoid(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    labels=[1.0,1.0,0.0], logits=[0.6,0.7,0.2], name=None\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.metrics.Sum at 0x1db3cdab588>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.metrics.Sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(5,) dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Variable(tf.zeros([5]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis=-1\n",
    "epsilon=0.000000001\n",
    "_x = np.random.rand(32,14)\n",
    "_x = tf.constant(_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2737, shape=(2, 14), dtype=float64, numpy=\n",
       "array([[0.18354011, 0.80482988, 0.72830186, 0.26298564, 0.69988818,\n",
       "        0.49241716, 0.40259916, 0.3139576 , 0.77811343, 0.08418105,\n",
       "        0.60443597, 0.21147113, 0.0755041 , 0.93938512],\n",
       "       [0.86974583, 0.63982098, 0.00433048, 0.45329378, 0.76117299,\n",
       "        0.94724667, 0.83008082, 0.65483281, 0.51133978, 0.32771291,\n",
       "        0.1799161 , 0.05013963, 0.13186533, 0.95416694]])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduction_axes = list(range(len(_x.get_shape())))\n",
    "reduction_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del reduction_axes[axis]\n",
    "reduction_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast_shape = [1] * len(_x.get_shape())\n",
    "broadcast_shape[axis] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 14]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcast_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2739, shape=(14,), dtype=float64, numpy=\n",
       "array([0.44129831, 0.48227416, 0.40288465, 0.53571309, 0.50323327,\n",
       "       0.57323386, 0.48644189, 0.54528739, 0.4613733 , 0.44390142,\n",
       "       0.54202612, 0.53564627, 0.46645622, 0.49391055])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = tf.reduce_mean(_x, axis=reduction_axes)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2835, shape=(1, 14), dtype=float64, numpy=\n",
       "array([[0.28816411, 0.29212979, 0.29721676, 0.26816005, 0.23223909,\n",
       "        0.28133979, 0.26817694, 0.28613305, 0.28368718, 0.32460106,\n",
       "        0.29742075, 0.27289657, 0.32352745, 0.30904081]])>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brodcast_mean = tf.reshape(mean, broadcast_shape)\n",
    "std = tf.reduce_mean(tf.square(_x - brodcast_mean) + epsilon, axis=reduction_axes)\n",
    "std = tf.sqrt(std)\n",
    "brodcast_std = tf.reshape(std, broadcast_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_normed = self.bn(_x)\n",
    "x_p = tf.keras.activations.sigmoid(self.beta * x_normed)\n",
    "\n",
    "\n",
    "alphas = tf.Variable(tf.zeros([14]), dtype=tf.float32)\n",
    "alphas\n",
    "\n",
    "\n",
    "alphas * (1.0 - x_p) * _x + x_p * _x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
