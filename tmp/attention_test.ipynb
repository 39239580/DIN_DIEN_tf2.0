{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as nn\n",
    "\n",
    "from layer import attention, dice, AUGRU\n",
    "from utils import sequence_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attention过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化层\n",
    "dim_layers = [36,1]\n",
    "fc = tf.keras.Sequential()\n",
    "for dim_layer in dim_layers[:-1]:\n",
    "    fc.add(nn.Dense(dim_layer, activation='sigmoid'))\n",
    "fc.add(nn.Dense(dim_layers[-1], activation=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "传入参数：其中queries是 item_join_emb,keys是hist_join_emb\n",
    "keys_length 是每个batch中user的序列长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造虚拟数据\n",
    "queries  = np.random.rand(32,8+6)\n",
    "keys = np.random.rand(32,20,8+6)\n",
    "keys_length = np.random.randint(1,21,(32,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了实现queries和keys的类似Attention查询机制，将queries进行复制，使得二者维度相同\n",
    "queries = tf.tile(tf.expand_dims(queries, 1), [1, tf.shape(keys)[1], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def printshape(name):\n",
    "#     print(name.shape)\n",
    "  \n",
    "# for i in [queries, keys, queries-keys, queries*keys]:\n",
    "#     printshape(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 20, 56])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "din_all  = tf.concat([queries, keys, queries-keys, queries*keys], axis=-1)\n",
    "din_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 1, 20])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将数据丢入全连接层训练\n",
    "outputs = tf.transpose(fc(din_all), [0,2,1])\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 1, 20])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练结果中有些是无效的history产生的，将其mask掉\n",
    "# 不能采用base模型的mask机制，无效值=0，会使得在最后的softmax中得到最终值为0.5。\n",
    "key_masks = tf.sequence_mask(keys_length, max(keys_length), dtype=tf.float32)  # [B, T]\n",
    "key_masks = tf.expand_dims(key_masks, 1)\n",
    "key_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 20, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddings = tf.ones_like(outputs) * (-2 ** 32 + 1)\n",
    "paddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行mask,无效的值用这个填充-2 ** 32 + 1，后期softmax时将会变成0\n",
    "outputs  = tf.where(key_masks, outputs, paddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 1, 20])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale\n",
    "outputs = outputs / ((6+8) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 1, 20])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activation\n",
    "outputs = tf.keras.activations.softmax(outputs, -1)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行数据类型转换\n",
    "outputs = tf.cast(outputs,dtype=tf.float32)\n",
    "keys = tf.cast(keys,dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted sum\n",
    "outputs = tf.squeeze(tf.matmul(outputs, keys))  # [B, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=133, shape=(32, 14), dtype=float32, numpy=\n",
       "array([[0.48441058, 0.5810695 , 0.5439096 , 0.36418653, 0.36395156,\n",
       "        0.4636144 , 0.60085315, 0.56507784, 0.51698405, 0.48451677,\n",
       "        0.44668573, 0.48170775, 0.4257315 , 0.57143736],\n",
       "       [0.5191581 , 0.6042936 , 0.4374274 , 0.39265877, 0.28725877,\n",
       "        0.40437052, 0.45542845, 0.5012349 , 0.43098414, 0.34788415,\n",
       "        0.41686141, 0.59862727, 0.45880666, 0.48151138],\n",
       "       [0.5191933 , 0.47186404, 0.4616608 , 0.49709198, 0.42934102,\n",
       "        0.53557587, 0.56539303, 0.4764052 , 0.53780836, 0.4523728 ,\n",
       "        0.4940291 , 0.55269784, 0.41719928, 0.56797355],\n",
       "       [0.54032695, 0.8907372 , 0.1367836 , 0.6305817 , 0.52380645,\n",
       "        0.38354266, 0.26662576, 0.31388074, 0.26164034, 0.4550085 ,\n",
       "        0.54338574, 0.45832253, 0.39412034, 0.75757045],\n",
       "       [0.48735633, 0.5731554 , 0.63998187, 0.61434305, 0.5733051 ,\n",
       "        0.5038809 , 0.62862283, 0.47936112, 0.4204821 , 0.5654786 ,\n",
       "        0.5793242 , 0.30579573, 0.5259613 , 0.5383043 ],\n",
       "       [0.3476018 , 0.12782346, 0.9824005 , 0.73220724, 0.15505756,\n",
       "        0.02176241, 0.5406549 , 0.14597544, 0.6727101 , 0.55603147,\n",
       "        0.5944375 , 0.5591573 , 0.66861033, 0.52412444],\n",
       "       [0.53347015, 0.5342814 , 0.51406074, 0.3455824 , 0.46968535,\n",
       "        0.45058566, 0.5224684 , 0.44677368, 0.40381128, 0.5338676 ,\n",
       "        0.5553113 , 0.37022907, 0.480302  , 0.5412262 ],\n",
       "       [0.55567646, 0.5873019 , 0.42926568, 0.38314772, 0.48440987,\n",
       "        0.594822  , 0.40928575, 0.50999   , 0.42506453, 0.33602643,\n",
       "        0.60417295, 0.5364578 , 0.5149493 , 0.45145857],\n",
       "       [0.39089194, 0.6044365 , 0.46604642, 0.41453454, 0.43215638,\n",
       "        0.5082116 , 0.4279888 , 0.5635761 , 0.5263234 , 0.50571007,\n",
       "        0.5628629 , 0.48158646, 0.5023273 , 0.5281434 ],\n",
       "       [0.56775886, 0.557511  , 0.51321507, 0.5538881 , 0.49473095,\n",
       "        0.60281545, 0.53823996, 0.53951883, 0.51915777, 0.49046385,\n",
       "        0.5682964 , 0.38672745, 0.5373623 , 0.44584265],\n",
       "       [0.44564986, 0.7224518 , 0.5071521 , 0.5627638 , 0.5243319 ,\n",
       "        0.53799593, 0.38629478, 0.53868294, 0.547899  , 0.6155287 ,\n",
       "        0.63232034, 0.56519085, 0.5168042 , 0.5182902 ],\n",
       "       [0.5979937 , 0.7715224 , 0.4664457 , 0.6994097 , 0.6084058 ,\n",
       "        0.44873148, 0.43494427, 0.2731227 , 0.4345234 , 0.44636488,\n",
       "        0.62542534, 0.29327625, 0.38412583, 0.62280077],\n",
       "       [0.5469577 , 0.54001015, 0.34176344, 0.53977853, 0.49207613,\n",
       "        0.5963673 , 0.50676596, 0.61547726, 0.67322916, 0.41691038,\n",
       "        0.5550334 , 0.46948346, 0.4856001 , 0.58059895],\n",
       "       [0.5090445 , 0.60624427, 0.6042744 , 0.43525827, 0.43487915,\n",
       "        0.45937702, 0.59168756, 0.54767215, 0.44119138, 0.53352857,\n",
       "        0.50981116, 0.47177148, 0.5372824 , 0.44967675],\n",
       "       [0.42014146, 0.6058186 , 0.8702881 , 0.38950634, 0.56504846,\n",
       "        0.81666315, 0.5331158 , 0.53387064, 0.6621338 , 0.5538744 ,\n",
       "        0.5830872 , 0.34506574, 0.37886894, 0.52646446],\n",
       "       [0.5226933 , 0.5260976 , 0.5321416 , 0.44424245, 0.5164726 ,\n",
       "        0.4772427 , 0.4349399 , 0.66440505, 0.54692733, 0.45809868,\n",
       "        0.625782  , 0.529948  , 0.61758476, 0.56145734],\n",
       "       [0.41238534, 0.36218163, 0.30877784, 0.5829625 , 0.43991944,\n",
       "        0.47894529, 0.54980683, 0.32973903, 0.36802253, 0.33251655,\n",
       "        0.50994265, 0.54017687, 0.40483642, 0.56089365],\n",
       "       [0.22307652, 0.52773416, 0.57041013, 0.69865215, 0.62697315,\n",
       "        0.8241391 , 0.6101966 , 0.62691355, 0.2305993 , 0.40528458,\n",
       "        0.5383077 , 0.48819432, 0.46018493, 0.5632523 ],\n",
       "       [0.43470106, 0.39648336, 0.42388445, 0.66218996, 0.3516132 ,\n",
       "        0.5942276 , 0.49269262, 0.5765726 , 0.4747618 , 0.44446203,\n",
       "        0.38286084, 0.51884735, 0.4146275 , 0.3804302 ],\n",
       "       [0.53788537, 0.43190476, 0.5544987 , 0.5123563 , 0.5678969 ,\n",
       "        0.4559205 , 0.40936333, 0.49937746, 0.50711125, 0.48426023,\n",
       "        0.4440511 , 0.34332496, 0.46575376, 0.442441  ],\n",
       "       [0.61781555, 0.58183515, 0.37484455, 0.5023096 , 0.41193008,\n",
       "        0.5036524 , 0.47318897, 0.57729906, 0.4287645 , 0.36788726,\n",
       "        0.64218426, 0.34990767, 0.51650006, 0.4706663 ],\n",
       "       [0.43010587, 0.5011224 , 0.66020346, 0.48617825, 0.51165557,\n",
       "        0.5013544 , 0.37732166, 0.542809  , 0.5026188 , 0.5258692 ,\n",
       "        0.57276523, 0.50381047, 0.4511954 , 0.65095025],\n",
       "       [0.6882581 , 0.6271349 , 0.42512494, 0.49898794, 0.59557855,\n",
       "        0.5378401 , 0.50388706, 0.51551425, 0.548544  , 0.3231415 ,\n",
       "        0.5721657 , 0.50601625, 0.61692595, 0.495373  ],\n",
       "       [0.42262986, 0.5312843 , 0.49686074, 0.4156903 , 0.53704613,\n",
       "        0.48921764, 0.48111674, 0.5061556 , 0.5202076 , 0.5227733 ,\n",
       "        0.58429587, 0.4888676 , 0.40004084, 0.561207  ],\n",
       "       [0.442389  , 0.68205893, 0.39188206, 0.52796584, 0.2981419 ,\n",
       "        0.6617171 , 0.5660211 , 0.6118953 , 0.48106262, 0.3593759 ,\n",
       "        0.57613754, 0.24375571, 0.57347685, 0.5382622 ],\n",
       "       [0.5350387 , 0.38817877, 0.3561409 , 0.6063838 , 0.473288  ,\n",
       "        0.52524686, 0.45067057, 0.46391034, 0.5469593 , 0.39588907,\n",
       "        0.60213745, 0.49519125, 0.459883  , 0.5943506 ],\n",
       "       [0.5005091 , 0.607636  , 0.5113359 , 0.4907121 , 0.56961787,\n",
       "        0.46913242, 0.48095596, 0.47658777, 0.6168017 , 0.439237  ,\n",
       "        0.49024498, 0.45382994, 0.44960192, 0.5194367 ],\n",
       "       [0.79908156, 0.24697629, 0.3843277 , 0.71346736, 0.20006672,\n",
       "        0.70090914, 0.7040825 , 0.7050957 , 0.76467717, 0.78836685,\n",
       "        0.06958503, 0.58089685, 0.22182532, 0.42576897],\n",
       "       [0.56219685, 0.44277757, 0.5336439 , 0.46453553, 0.45935225,\n",
       "        0.5226619 , 0.5156149 , 0.55802155, 0.49841216, 0.439378  ,\n",
       "        0.35521615, 0.45505112, 0.4461881 , 0.37746322],\n",
       "       [0.46008685, 0.5049904 , 0.54689217, 0.4542511 , 0.4516016 ,\n",
       "        0.48423588, 0.6048791 , 0.5851919 , 0.457762  , 0.64970416,\n",
       "        0.53434384, 0.50983196, 0.6380387 , 0.43680808],\n",
       "       [0.5162269 , 0.45795664, 0.60919654, 0.45582706, 0.54295594,\n",
       "        0.5506232 , 0.410534  , 0.5356851 , 0.5872105 , 0.51375866,\n",
       "        0.5469423 , 0.45133033, 0.4626384 , 0.48165417],\n",
       "       [0.5322293 , 0.539657  , 0.45997444, 0.50147176, 0.48707744,\n",
       "        0.46144792, 0.5331069 , 0.49789417, 0.55444247, 0.3231079 ,\n",
       "        0.6037804 , 0.42843872, 0.6238306 , 0.52372247]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
